{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdL1ZvDepO-X"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_pemiL8pO-Y"
   },
   "source": [
    "# T81-559: Applications of Generative AI\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/index.html)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Module 8 Assignment: Kaggle-like Assignment**\n",
    "\n",
    "**Student Name: Your Name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lky4xopspO-Z"
   },
   "source": [
    "# Assignment Instructions\n",
    "\n",
    "One of the major assignments in this course is a Kaggle competition. Each semester, I create a new dataset for each course I teach to try. Kaggle competitions typically provide two files: testing and training datasets. I will give you two files for this assignment, which you can see here.\n",
    "\n",
    "* [Training Dataset](https://data.heatonresearch.com/data/t81-559/assignments/riddles_train.csv)\n",
    "* [Testing Dataset](https://data.heatonresearch.com/data/t81-559/assignments/riddles_test.csv)\n",
    "\n",
    "You will make use of the training dataset to train your model. For this assignment, I do not suggest you train a model; instead, I recommend examining the training dataset to get an idea of the input and expected output. The training dataset will always contain both the input (riddle, in this case) and the expected output (answer, in this case). The testing dataset has no \"answer\" column, which is the expected output. You will use the riddle to predict the answer for the testing dataset.\n",
    "The training dataset looks like the following:\n",
    "\n",
    "|riddle|answer|\n",
    "|---|---|\n",
    "|I am tall when I am young, and short when I am old. What am I?|candle|\n",
    "|What has keys but can't open locks?|piano|\n",
    "|I have branches, but no fruit, trunk or leaves. What am I?|bank|\n",
    "|...|...|\n",
    "\n",
    "Notice how the file provides the answer for the training dataset.\n",
    "\n",
    "The testing dataset looks like the following:\n",
    "\n",
    "|riddle|\n",
    "|---|\n",
    "|What has to be broken before you can use it?|\n",
    "|The more you have of it, the less you see. What is it?|\n",
    "|What gets wetter the more it dries?|\n",
    "|...|\n",
    "\n",
    "Notice how it provides the riddles but not their answers.\n",
    "\n",
    "|riddle|answer|\n",
    "|---|---|\n",
    "|What has to be broken before you can use it?|egg|\n",
    "|\"The more you have of it, the less you see. What is it?\"|darkness|\n",
    "|What gets wetter the more it dries?|towel|\n",
    "|...|...|\n",
    "\n",
    "Your assignment is to use an LLM to determine the answer for each item in the training dataset. You are to produce a submission data frame that will look like the following:\n",
    "\n",
    "Please keep in mind the following for this assignment.\n",
    "\n",
    "You will need to craft your prompt so that your answer is something like \"banana,\" not \"a banana\" or \"a banana.\"\n",
    "You do not need to use agents or tools.\n",
    "You do not need to train a model; look at the training data to get an idea of the answers. You will submit based on the test data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4LQZW_SpO-Z"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZnCEIEopO-Z",
    "outputId": "cf1579d0-12c6-4351-a77f-e38eb63aac18"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "  from google.colab import drive, userdata\n",
    "  drive.mount('/content/drive', force_remount=True)\n",
    "  COLAB = True\n",
    "  print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "  print(\"Note: not using Google CoLab\")\n",
    "  COLAB = False\n",
    "\n",
    "# Assignment Submission Key - Was sent you first week of class.\n",
    "# If you are in both classes, this is the same key.\n",
    "if COLAB:\n",
    "  # For Colab, add to your \"Secrets\" (key icon at the left)\n",
    "  key = userdata.get('T81_559_KEY')\n",
    "else:\n",
    "  # If not colab, enter your key here, or use an environment variable.\n",
    "  # (this is only an example key, use yours)\n",
    "  key = \"Gx5en9cEVvaZnjhdaushddhuhhO4PsI32sgldAXj\"\n",
    "\n",
    "# OpenAI Secrets\n",
    "if COLAB:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# Install needed libraries in CoLab\n",
    "if COLAB:\n",
    "    !pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMLHwV0hpO-a"
   },
   "source": [
    "# Assignment Submit Function\n",
    "\n",
    "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems.\n",
    "\n",
    "**It is unlikely that should need to modify this function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozSyLCNtpO-a"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import io\n",
    "from typing import List, Union\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - List of pandas dataframes or images.\n",
    "# key - Your student key that was emailed to you.\n",
    "# course - The course that you are in, currently t81-558 or t81-559.\n",
    "# no - The assignment class number, should be 1 through 10.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "\n",
    "def submit(\n",
    "    data: List[Union[pd.DataFrame, PIL.Image.Image]],\n",
    "    key: str,\n",
    "    course: str,\n",
    "    no: int,\n",
    "    source_file: str = None\n",
    ") -> None:\n",
    "    if source_file is None and '__file__' not in globals():\n",
    "        raise Exception(\"Must specify a filename when in a Jupyter notebook.\")\n",
    "    if source_file is None:\n",
    "        source_file = __file__\n",
    "\n",
    "    suffix = f'_class{no}'\n",
    "    if suffix not in source_file:\n",
    "        raise Exception(f\"{suffix} must be part of the filename.\")\n",
    "\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb', '.py']:\n",
    "        raise Exception(f\"Source file is {ext}; must be .py or .ipynb\")\n",
    "\n",
    "    with open(source_file, \"rb\") as file:\n",
    "        encoded_python = base64.b64encode(file.read()).decode('ascii')\n",
    "\n",
    "    payload = []\n",
    "    for item in data:\n",
    "        if isinstance(item, PIL.Image.Image):\n",
    "            buffered = io.BytesIO()\n",
    "            item.save(buffered, format=\"PNG\")\n",
    "            payload.append({'PNG': base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
    "        elif isinstance(item, pd.DataFrame):\n",
    "            payload.append({'CSV': base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported data type: {type(item)}\")\n",
    "\n",
    "    response = requests.post(\n",
    "        \"https://api.heatonresearch.com/wu/submit\",\n",
    "        headers={'x-api-key': key},\n",
    "        json={\n",
    "            'payload': payload,\n",
    "            'assignment': no,\n",
    "            'course': course,\n",
    "            'ext': ext,\n",
    "            'py': encoded_python\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Success: {response.text}\")\n",
    "    else:\n",
    "        print(f\"Failure: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "H7kgvLHspO-a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Assignment Sample Code\n",
    "\n",
    "The following code provides a starting point for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8ZPLGWgkpO-a",
    "outputId": "50781ea9-7799-4ac1-f780-e6a0eec62124"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import string\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# You must identify your source file.  (modify for your local setup)\n",
    "file=\"/content/drive/My Drive/Colab Notebooks/assignment_yourname_t81_559_class8.ipynb\"  # Google CoLab\n",
    "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_559_deep_learning\\\\assignments\\\\assignment_yourname_t81_559_class8.ipynb'  # Windows\n",
    "# file='/Users/jheaton/projects/t81_559_deep_learning/assignments/assignment_yourname_t81_559_class8.ipynb'  # Mac/Linux\n",
    "\n",
    "# Begin assignment\n",
    "\n",
    "df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-559/assignments/riddles_test.csv\")\n",
    "df.head()\n",
    "\n",
    "## ... continue your code...\n",
    "\n",
    "## Submit assignment\n",
    "submit(source_file=file,data=[df_submit],course='t81-559',key=key,no=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWesp8WFUUDc",
    "outputId": "cf3080da-a35e-4cf6-88c7-7d094bce4315"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (genai)",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
